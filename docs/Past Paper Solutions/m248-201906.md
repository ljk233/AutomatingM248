---
title: "M248 June 2019"
date: 2021-04-22
---

## Section A

### q.01

**E.**
*Checking the validity of a probability function (HB p.7) : discrete*

A. No, $\sum x \neq 1$

B. No, $p(2) \leq 0$

C. No, $p(2) \leq 0$

D. No, $\sum x \neq 1$

E. Yes, satisfies both properties.

F. No, $\sum x \neq 1$

### q.02

**C.**
*Calculating probabilities using a probability function (HB p.7) : p.d.f.*

The probability $P(2 \leq X \leq 4)$ is given by

$$
\begin{aligned}
    P(2 \leq X \leq 4) = \int_{2}^{4} \frac{5}{4x^{2}} \> dx &= \frac{5}{4} \int_{2}^{4} x^{-2} \> dx \\
    &= \frac{5}{4} \bigg[-x^{-1} \bigg]_{2}^{4} \\
    &= -\frac{5}{4} \bigg(\frac{1}{4} - \frac{1}{2} \bigg) \\
    &= \frac{5}{16} \\
\end{aligned}
$$

### q.03

**A.**
*Normalising constants (Book A, p.111)*

Normalising constant $K$ is given by

$$
    1 = \int_{-1}^{1} \frac{1}{K} \bigg( 1 + \frac{x}{2} \bigg) \> dx
      = \frac{1}{K} \int_{-1}^{1} 1 + \frac{x}{2} \> dx.
$$

Therefore,

$$
K = \int_{-1}^{1} 1 + \frac{x}{2} \> dx
  = \bigg[ x + \frac{1}{2} \bigg(\frac{x^{2}}{2} \bigg) \bigg]_{-1}^{1}
  = \bigg\{ 1 + \frac{1}{4} (1^{2}) - \bigg( -1 + \frac{1}{4} (-1)^{2} \bigg) \bigg\}
  = 2
$$

### q.04

**E.**
*Calculating probabilities using the c.d.f. : discrete*

The c.d.f. of $X$ at $x=3$ is given by

$$
F(x=3) = P(X \leq 3) = p(1) + p(2) + p(3) = 0.1 + 0.3 + 0.2 = 0.6.
$$

### q.05

**E.**
*Poisson distribution (HB p.8)*

The $P(X>2) = 1 - P(X \leq 2)$ is given by,

$$
\begin{aligned}
1 - P(X \leq 2) &= 1 - p(0) + p(1) + p(2) \\
  &= 1 - \sum_{i=0}^{2} e^{-\mu} \bigg( \frac{\mu^{x_{i}}}{x_{i}!} \bigg) \\
  &= 1 - e^{-\mu} \sum_{i=0}^{2} \bigg( \frac{\mu^{x_{i}}}{x_{i}!} \bigg) \\
  &= 1 - e^{-0.4} \bigg( \frac{0.4^{0}}{0!} + \frac{0.4^{1}}{1!} + \frac{0.4^{2}}{2!} \bigg) \\
  &= 1 - 1.48 e^{-0.4}.
\end{aligned}
$$

### q.06

**F.**
*Mean of a linear function of rvs (HB p.9)*

For a random variable $Y=-2-2X$, then

$$
E(Y) = aE(X) + b,
$$

where $E(X) = 10$, $a = -2$, and $b=-2$.
Therefore,

$$
E(Y) = -2 (10) + (-2) = -20 - 2 = -22.
$$

### q.07

**E.**
*Variance of a linear function of rvs (HB p.9)*

For a random variable $Y=-2-2X$, then

$$
S(Y) = \sqrt{V(Y)} = \sqrt{a^{2} V(X)} = |a| \sqrt{V(X)},
$$

where $V(X) = 9$ and $a = -2$.
Therefore

$$
S(Y) = |-2| \sqrt{9} = 6.
$$

### q.08

**B.**
*Poisson approximation of rare events (HB p.10)*

It is estimated that $p=1/420$ suffer from the disease and $n=2100$ employees work for the company.
Therefore, as $n \geq 50$ and $p \leq 0.05$, the approximate number of employees who suffer from the disease at the company will be distributed

$$
B \bigg( 2100, \frac{1}{420} \bigg)
  \approx \text{Poisson} (np)
  \sim \text{Poisson} (5)
$$

### q.09

**C.**
*Poisson process (HB p.10) and Poisson distribution (HB p.8)*

Let $X$ model the number of email arriving in the office per hour.
Then $X \sim \text{Poisson}(\mu)$, where $\mu = 3$ is the average number of emails received in an hour.

The probability $P(X=4)$ is given by

$$
\begin{aligned}
  p(4) = e^{-3} \bigg( \frac{3^{4}}{4!} \bigg) \simeq 0.168.
\end{aligned}
$$

### q.10

**B.**
*Poisson process (HB p.10) and Exponential distribution (HB p.10)*

Let $T$ model the waiting time between emails arriving in the office.
Then $T \sim M(\lambda)$, where $\lambda = 3$ is the average number of emails received in an hour.

Fifteen minutes is $1/4$ hours, so $P(T < 1/4)$ is given by

$$
\begin{aligned}
  P \bigg(T \leq \frac{1}{4} \bigg) = F\bigg(\frac{1}{4}\bigg) = 1 - e^{-3 \big( \frac{1}{4} \big)} \simeq 0.528.
\end{aligned}
$$

### q.11

**F.**
*Poisson process (HB p.10)*

The number of emails that will arrive in 6 hours is distributed $\text{Poisson}(\lambda t)$, where $\lambda = 3, t=6$.
So $\text{Poisson}(18)$.

### q.12

*Bernoulli process (HB p.10) and Exponential distribution (HB p.10)*

B. **False**, in a **Bernoulli** process, events occur in discrete trials.

F. **False**, if $X$ has an *exponential distribution* then $X \sim M(\lambda)$, and so $E(X) = 1/\lambda$.

### q.13

**C.**
*Population quantiles rv (HB p.11) : continuous*

The $\alpha$-quantile of a continuous rv $X$ with c.d.f. $F(X)$ is defined as $F(x) = \alpha$.

If $F(x) = 2 - 10/x$ and $\alpha = 1/2$, then

$$
\begin{aligned}
  F(x) = \alpha \to 2 - \frac{10}{x} &= \frac{1}{2} \\
    2 - \frac{1}{2} &= \frac{10}{x} \\
    \frac{3}{2} &= \frac{10}{x} \\
    3x &= 20 \\
    x &= \frac{20}{3}.
\end{aligned}
$$

### q.14

**E.**
*Population quantiles of a discrete rv (HB p.11)*

The smallest value of $x \in X$ to satisfy $F(X) = q_{U} = 3/4$ is $x=5$.

### q.15

**A.**
*Difference between two independent normal rvs (HB p.11)*

If $X \sim N(4,3)$, $Y \sim N(2,2)$, then $U = X - Y$ will also be distributed normally with parameters:

$$
E(U) = E(X-Y) = E(X) - E(Y) = 4 - 2 = 2,
$$

and

$$
V(U) = V(X-Y) = V(X) + V(Y) = 3 + 2 = 5.
$$

So $U = X - Y \sim N(2, 5)$.

### q.16

**D.**
*Probabilities for a normal distribution (HB p.12)*

If $X \sim N(22, 36)$, then the probability $P(X > 25)$ is given by

$$
\begin{aligned}
P(X > 25) &= 1 - P\bigg(Z < \frac{25-22}{\sqrt{36}} \bigg) \\
  &= 1 - P\bigg(Z < \frac{1}{2} \bigg) \\
  &= 1 - \Phi(0.50) \\
  &\simeq 1 - 0.6915 = 0.3085.
\end{aligned}
$$

### q.17

**F.**
*Quantiles of a normal distribution (HB p.12)*

The volume of the container (in ml) that ensures overflow will only occur 1% of the time corresponds to the 0.99-quantile of the distribution of $X \sim N(1748.48, 20^{2})$, such that

$$
x = \sigma q_{0.99} + \mu,
$$

where $q_{0.99} = 2.326$ is the 0.99-quantile of the standard normal distribution.

Therefore,

$$
x = 20 (2.326) + 1748.48 = 1795.00.
$$

### q.18

**A.**
*Distribution of the mean (HB p.12) and Probabilities for a normal distribution (HB p.12)*

If $X \sim N(10000, 500^{2})$, then $\overline{X}_{50}$ will be distributed

$$
E(\overline{X}_{50}) = \mu = 10000,
$$

and

$$
V(\overline{X}_{50}) = \frac{\sigma^{2}}{n} = \frac{500^{2}}{50} = 5000.
$$

Therefore the probability $P(\overline{X}_{50} < 9900)$ will be given by

$$
\begin{aligned}
  P(X < 9900) &= 1 - P \bigg( Z < \frac{9900-10000}{\sqrt{5000}} \bigg) \\
    &= P\bigg(Z < -\sqrt{2} \bigg) \\
    &\simeq \Phi(-1.41) \\
    &= 1 - \Phi(1.41) \\
    &= 1 - 0.9207 = 0.0793.
\end{aligned}
$$

### q.19

**A.**
*Mean of an unbiased estimator (HB p.13)*

If $E(X_{1}) = \theta$, $E(X_{2}) = 2\theta$, and $E(X_{3}) = 6\theta$, then an unbiased estimator for $\theta$ is such that $E(\widehat \theta) = \theta$.

Looking at option A,

$$
\begin{aligned}
  E(\widehat \theta) &= E\bigg\{ \frac{1}{10}(2 X_{1} + X_{2} + X_{3}) \bigg\} \\
    &= \frac{1}{10} E\bigg\{ (2 X_{1} + X_{2} + X_{3}) \bigg\} \\
    &= \frac{1}{10} \{ E (2 X_{1}) + E (X_{2}) + E (X_{3}) \} \\
    &= \frac{1}{10} \{ 2 E (X_{1}) + E (X_{2}) + E (X_{3}) \} \\
    &= \frac{1}{10} \{ 2 \theta + 2 \theta + 6 \theta \} \\
    &= \frac{1}{10} \{ 10 \theta \} \\
    &= \theta.
\end{aligned}
$$

### q.20

**C.**
*Exact CI for a normal mean (HB p.15)*

The upper limit of an exact 99% confidence interval for the mean $\mu^{+}$ is given by

$$
\mu^{+} = \overline{x} + t \frac{s}{\sqrt{n}},
$$

where $t$ is the $(1-(\alpha/2))$-quantile of $t(n-1)$.

Here we have $\overline{x}=112.5$, $n=10$, and $s=35.1$.
The value $t=3.250$ is the $0.995$-quantile of the $t(9)$ distribution.
So the upper limit is given by

$$
\begin{aligned}
  \mu^{+} = 112.5 + 3.250 \bigg( \frac{35.1}{\sqrt{10}} \bigg) \simeq 148.6
\end{aligned}
$$

### q.21

**C and F.**
*Anatomy of a hypothesis test (HB p.17) and $z$-test (HB p.17)*

C. True, as the significance level decreases, the rejection region increases.

F. True

### q.22

**B.**
*Calculating the test statistic for a $z$-test (HB p.17)*

The test statistic is

$$
  Z = \frac{\overline{X} - \mu_{0}}{S/\sqrt{n}} = \frac{434.2 - 433}{1.1/\sqrt{36}} \simeq 6.55.
$$

### q.23

**D.**
*Calculating the power of a test (HB p.18)*

The power of this two-sided test with a 5% significance level will be

$$
1 - \Phi \bigg( q_{1-(\alpha/2)} - \frac{d}{\sigma/\sqrt{n}} \bigg)
$$

where $q_{1-(\alpha/2)} = q_{0.975} = 1.960$, $d=0.6$, $\sigma=4.2$, and $n=196$.
Therefore,

$$
\begin{aligned}
 1 - \Phi \bigg( 1.960 - \frac{0.6}{4.2/\sqrt{196}} \bigg)
  &\simeq 1 - \Phi (-0.4) \\
  &= 1 - (1 - \Phi (0.4) \\
  &= \Phi (0.4) \\
  &= 0.5160.
\end{aligned}
$$

### q.24

**C.**
*Chi-squared goodness-of-fit test (HB p.21)*

The degrees of freedom of a **chi-squared** goodness-of-fit test is $k-p-1$, where $k=4$ is the number of categories, and $p=0$ is the number of estimated parameters.

Therefore the degrees of freedom is $4-0-1=3$.

### q.25

**F.**
*Chi-squared goodness-of-fit test (HB p.21)*

The **chi-squared** test statistic is

$$
\chi^{2} = \sum\frac{(O_{i} - E{i})^{2}}{E_i},
$$

so

$$
\chi^{2} = \frac{4.1^{2}}{106.9} + \dots + \frac{(-3.9)^{2}}{11.9} \simeq 1.53.
$$

### q.26

**B.**
*Least squares estimate (HB 22) : intercept*

The least squares estimate of $\beta$ is

$$
\beta = \frac{S_{xy}}{S_{xx}} = \frac{962.35}{457.44} = 2.10377 \ldots
$$

Therefore, the least squares estimate of the intercept, $\alpha$, is

$$
\alpha = 31.96 − 2.10377 (12.34) \simeq 6.00.
$$

### q.27

**A and E.**
*Hypothesis test of $\widehat{\beta}$ (HB p.22)*

### q.28

**A and F.**
*Transformations (HB p.23) : skew data*

The data is left skew, so we go up the ladder of powers.

### q.29

**A.**
*Using a fitted model (HB p.21)*

The fitted model is $\log{y} = 0.423 + 0.0325 x$, so when $x=30$,

$$
y = e^{0.423 + 0.0325(30)} = e^{1.398} = 4.047.
$$

## Section B

### q.30

*Finding the c.d.f. of a rv : continuous*

If $f(x) = \frac{1}{78} (6x^{2} + 2x + 5)$, where $x \in (0,3)$, then the $F(x)$ will be,

$$
\begin{aligned}
F(x) = \int_{0}^{x} \frac{1}{78} (6y^{2} + 2x + 5) \> dy
  &= \frac{1}{78} \bigg[ \frac{6}{3} y^{3} + \frac{2}{2} y^{2} + 5y \bigg]_{0}^{x} \\
  &= \frac{1}{78} \bigg[ 2 y^{3} + y^{2} + 5y \bigg]_{0}^{x} \\
  &= \frac{1}{78} ( 2 x^{3} + x^{2} + 5x - (0 + 0 + 0)) \\
  &= \frac{1}{78} (2 x^{3} + x^{2} + 5x).
\end{aligned}
$$

### q.31

*Calculating probabilities using the c.d.f. (HB p.7) : continuous*

If $F(x) = \frac{1}{80} (x^{2} + x^{3})$, then $P(1 \leq X \leq 2) = F(2) - F(1)$ is given by

$$
\begin{aligned}
F(2) - F(1) &= \frac{1}{80} (2^{2} + 2^{3}) - \frac{1}{80} (1^{2} + 1^{3}) \\
  &= \frac{1}{80} (10) \\
  &= \frac{1}{8}.
\end{aligned}
$$

### q.32

#### (a)

*Geometric distribution (HB p.8)*

Let $X$ be a discrete rv that represents the number of people who need to pass through the metal detector until the next to activate it.
Then $X$ is modelled by the geometric distribution, $X \sim G(p)$, where $p=0.2$ is the probability that an individual activates the metal detector, so $X \sim G(0.4)$.

The probability $P(X=4)$ is given by

$$
\begin{aligned}
  P(X=4) = (1-p)^{y-1} p = 0.8^{3} 0.2 = 0.1024.
\end{aligned}
$$

#### (b)

*Binomial distribution (HB p.8)*

Let $Y$ be a discrete rv that represents the number of people that passes through the metal detector.
Then $Y$ is modelled by the binomial distribution, $Y \sim B(n,p)$, where $n=10$ is the sample size and $p=0.2$ is the probability that an individual sets off the metal detector, so $Y \sim B(10,0.2)$.

The probability $P(Y=3)$ is given by

$$
\begin{aligned}
  P(Y=3) = \binom{n}{y} p^y (1-p)^{n-y} = \binom{10}{3} 0.2^{3} (0.8)^{7} \simeq 0.2013.
\end{aligned}
$$

### q.33

#### (a)

*Mean of a rv (HB p.9) : continuous*

The expected value $E(X)$ of a continuous random variable $X$ is defined as

$$
E(X) = \int_{L}^{U} x \> f(x) \> dx, \hspace{3mm} x \in (L, U).
$$

Therefore,

$$
\begin{aligned}
  E(X) = \int_{0}^{1} x \frac{3}{2} (1 - x^{2}) &= \frac{3}{2} \int_{0}^{1} x - x^{3} \> dx \\
    &= \frac{3}{2} \bigg[ \frac{1}{2} x^{2} - \frac{1}{4} x^{4} \bigg]_{0}^{1} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{2} (1)^{2} - \frac{1}{4} (1)^{4} - \bigg( \frac{1}{2} (0)^{2} - \frac{1}{4} (0)^{4} \bigg) \bigg\} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{4} \bigg\} \\
    &= \frac{3}{8}. \\
\end{aligned}
$$

Hence, $E(X)=3/8$.

#### (b)

*Variance of a rv (HB p.9) : continuous*

The $E(X^{2})$ of a continuous random variable $X$ is defined as

$$
E(X^{2}) = \int_{L}^{U} x^{2} \> f(x) \> dx, \hspace{3mm} x \in (L, U).
$$

Therefore,

$$
\begin{aligned}
  E(X^{2}) = \int_{0}^{1} x^{2} \frac{3}{2} (1 - x^{2}) &= \frac{3}{2} \int_{0}^{1} x^{2} - x^{4} \> dx \\
    &= \frac{3}{2} \bigg[ \frac{1}{3} x^{3} - \frac{1}{5} x^{5} \bigg]_{0}^{1} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{3} (1)^{3}- \frac{1}{5} (1)^{5} - \bigg( \frac{1}{3} (0)^{3} - \frac{1}{5} (0)^{5} \bigg) \bigg\} \\
    &= \frac{3}{2} \bigg( \frac{1}{15} \bigg) \\
    &= \frac{1}{5}. \\
\end{aligned}
$$

Hence, $E(X^{2})=1/5$.

#### (c)

*Variance of a rv (HB p.9) : continuous*

The variance $V(X)$ of a continuous random variable $X$ is defined as

$$
V(X) = E\{ (X-\mu)^{2} \} = E(X^{2}) - E(X)^{2}
$$

We know that $E(X) = 3/5$, $E(X^{2})=1/5$, so

$$
V(X) = \frac{1}{5} - \bigg( \frac{3}{8} \bigg)^{2}
  = \frac{1}{5} - \frac{9}{64} = \frac{19}{320} \simeq 0.0594.
$$

Therefore, $V(X)=19/320 \simeq 0.0594$, rounded to 3sf.

### q.34

#### (a)

*Finding the likelihood function of a sample (HB p.13) : discrete*

Using the p.m.f. of a geometric distribution, if $p(x_{i}; \theta) = \theta(1-\theta)^{x_{i}-1}$, then the likelihood of $\theta$, $L(\theta)$, will be

$$
\begin{aligned}
  L(\theta) = \prod_{i=1}^{4} p(x_{i}; \theta) &= \theta(1-\theta)^{x_{1}-1} \times \theta(1-\theta)^{x_{2}-1} \times \theta(1-\theta)^{x_{3}-1} \times \theta(1-\theta)^{x_{4}-1} \\
    &= \theta(1-\theta)^{5-1} \times \theta(1-\theta)^{2-1} \times \theta(1-\theta)^{5-1} \times \theta(1-\theta)^{1-1} \\
    &= \theta \times \theta \times \theta \times \theta \times (1-\theta)^{4} \times (1-\theta)^{1} \times (1-\theta)^{4} \times (1-\theta)^{0} \\
    &= \theta^{4}  \times (1-\theta)^{4 + 1 + 4 + 0} \\
    &= (1-\theta)^{9} \theta^{4}. \\
\end{aligned}
$$

#### (b)

*Finding the MLE of an estimator (HB p.13)*

If $L(\theta) = (1-\theta)^{9} \theta^{4}$ then, by the **product rule**, $L'(\theta)$ will be given by

$$
\begin{aligned}
  L'(\theta) &= (1-\theta)^{9} \times 4 \theta^{3} + (-1) (9) (1-\theta)^{8} \theta^{4} \\
    &= 4 \theta^{3} (1-\theta)^{9} - 9 \theta^{4}  (1-\theta)^{8} \\
    &= \theta^{3} (1-\theta)^{8} ( 4 (1-\theta) - 9 \theta ) \\
    &= \theta^{3} (1-\theta)^{8} ( 4 - 4 \theta - 9 \theta ) \\
    &= (1-\theta)^{8} \theta^{3} ( 4 - 13 \theta ) \\
\end{aligned}
$$

This matches the expression given in the question.

#### (c)

*Finding the MLE of an estimator (HB p.13)*

The MLE of $\theta$, $\widehat \theta$, is the solution to

$$
L'(\theta) = (1-\theta)^{8} \theta^{3} ( 4 - 13 \theta ) = 0.
$$

Given the range of $\theta > 0$, then $\theta^{3}(1-\theta)^{8} > 0$, so this reduces to solving

$$
\begin{aligned}
  0 &= 4 - 13 \theta \\
  13 \> \theta  &= 4 \\
  \theta  &= \frac{4}{13} \simeq 0.3077.
\end{aligned}
$$

So $\widehat \theta \simeq 0.3077$.

### q.35

#### (a)

*CI for the difference between two proportions (HB p.15)*

Let $n_{1} = 100, x_{1} = 33$ represent the sample from 2010, and $n_{2} = 150, x_{2} = 54$ represent the sample from 2013.
Then the point estimate of the difference $\widehat d$ between the two samples is

$$
\widehat d = p_{1} - p_{2} = \frac{33}{100} - \frac{54}{150} = 0.33 - 0.36 = -0.03.
$$

Therefore, an approximate *95%* confidence interval for the population difference,
$(d^{-}, d^{+})$, is given by

$$
\begin{aligned}
d^{-} &= -0.03 - 1.96 \sqrt{ \frac{0.33(0.67)}{100} + \frac{0.36(0.64)}{150} }
  \simeq -0.15, \\
d^{+} &= -0.03 + 1.96 \sqrt{ \frac{0.33(0.67)}{100} + \frac{0.36(0.64)}{150} } \simeq 0.09.
\end{aligned}
$$

Therefore, a realised approximate 95% confidence interval for this scenario would be $(-0.15, 0.09)$.

#### (b)

*Repeated experiments interpretation of confidence intervals (HB p.14)*

If this entire trial was repeated independently a large number of times, and on each occasion a 95% confidence interval for the difference between proportions were calculated, then about 95% of these intervals would contain the population value for the difference between the proportion of individuals that thought cannabis should be legalised in 2010 and the proportion of individuals that thought cannabis should be legalised in 2013.

#### (c)

*Interpreting confidence intervals (M248 Unit 8, activity 14)*

The approximate 95% confidence interval found was $(-0.15, 0.09)$.
Given this interval contains $0$, it suggests that there is no difference in the proportion of individuals that thought cannabis should be legalised between 2010 and 2013.

### q.36

#### (a)

*The Wilcoxon signed rank test (HB p.19)*

Let $m$ denote the underlying population median difference in aluminium concentrations between August and November.
This is a two-sided test so the hypotheses are

$$
H_{0} : m = 0, \>  H_{1} : m \neq 0
$$

#### (b)

*The Wilcoxon signed rank test (HB p.19)*

| Tree                      | 1    | 2    | 3   | 4   | 5   | 6   | 7   | 8   | 9    | 10   | 11  | 12   | 13   |
|---------------------------|------|------|-----|-----|-----|-----|-----|-----|------|------|-----|------|------|
| Difference                | 12.0 | 12.3 | 3.1 | 7.2 | 5.3 | 1.0 | 6.3 | 0.0 | −2.2 | 23.4 | 2.0 | −1.2 | −5.6 |
| Sign of diff              | +    | +    | +   | +   | +   | +   | +   |     | -    | +    | +   | -    | -    |
| Abs value of diff         | 12.0 | 12.3 | 3.1 | 7.2 | 5.3 | 1.0 | 6.3 | 0.0 | 2.2  | 23.4 | 2.0 | 1.2  | 5.6  |
| Rank of abs value of diff | 10   | 11   | 5   | 9   | 6   | 1   | 8   |     | 4    | 12   | 3   | 2    | 7    |

The value of the test statistic is the sum of the ranks of the positivie differences, so

$$
w_{+} = 10 + 11 + 5 + 9 + 6 + 1 + 8 + 12 + 3 = 65.
$$

#### (c)

*Normal approximation of the Wilcoxon test statistic (HB p.20)*

Under the null hypothesis, for a sample of size $12$ (excluding the zero difference), the Wilcoxon signed rank test statistic $W_{+}$ has mean,

$$
\begin{aligned}
  E(W_{+}) = \frac{n(n+1)}{4} = \frac{12(13)}{4} = 39,
\end{aligned}
$$

and variance,

$$
\begin{aligned}
  V(W_{+}) = \frac{n(n+1)(2n+1)}{24} = \frac{12(13)(25)}{24} = 162.5.
\end{aligned}
$$

#### (d)

*Normal approximation of the Wilcoxon test statistic (HB p.20) and Interpreting $p$-values (HB p.18)*

In this scenario, the observed sum of ranks for the positive differences is $w_{+} = 65$, so the corresponding observed value of $Z$ is

$$
Z = \frac{w_{+} - E(W_{+})}{\sqrt{V(W_{+})}} = \frac{65-39}{\sqrt{162.5}} = 2.0396 \ldots \simeq 2.04.
$$

Using the table of probabilities of the standard normal distribution in the handbook gives

$$
P(Z \geq 2.04) = 1 - P(Z \leq 2.04) = 1 - 0.9793 = 0.0207.
$$

So, according to the approximation, the probability of obtaining a Wilcoxon signed rank test statistic of $65$ or greater is approximately $0.0207$.
For a two-sided test, the $p$-value is double this, so

$$
P(Z \leq -2.04) + P(Z \geq 2.04) = 2 P(Z \geq 2.04) = 0.0414.
$$

Given that $p=0.0414$, there is moderate against the null hypothesis that there is no difference in aluminium concentrations in the wood of trees between August and November.
The test statistic is greater than zero, so it suggests that the population median difference in aluminium concentrations between August and November is greater than zero, suggesting that there is an increase in Aluminium concentrations.

### q.37

#### (a)

*Interpreting the regression coefficients in multiple linear regression*

If the value of the percentage of individuals who earned \$3500 or more for each occupation increased ($x_{1}$) by one percentage point and the value of the percentage of individuals who were high school graduates ($x_{2}$) remains fixed, then the measure of prestige for each occupation would be expected to rise by 0.599

#### (b)

*Using a fitted model (HB p.22) to find the residual value*

Using the fitted model, a small company with $x_{1} = 8$ and $x_{2} = 64$ is predicted to have annual profits (in £100,000s)

$$y = 0.930 - 0.3662 (8) + 0.03543 (64) \simeq 0.268.$$

Given the actual value was $y=0.292$, this gives a residual value of

$$
w = 0.292 - 0.268 = 0.024.
$$

### q.38

==Not answered==
