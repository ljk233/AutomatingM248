---
title: "M248 June 2019"
date: '2021-04-27'
---

## Updates

**2021-04-27:**

## Setup

Path to script: **ljk233/AutomatingM248/src/r/calculators.r**

```{r setup}
source("../src/r/calculators.r")
source("../src/r/confint.r")
```

## Section A

### q.01

**E.**
*Checking the validity of a probability mass function (HB p.7)*

A. No, $\sum x \neq 1$

B. No, $p(2) \leq 0$

C. No, $p(2) \leq 0$

D. No, $\sum x \neq 1$

E. Yes, meets both properties.

F. No, $\sum x \neq 1$

### q.02

**C.**
*Calculating a probability using probability density functions (HB p.7)*

The probability $P(2 \leq X \leq 4)$ is given by

$$
\begin{aligned}
    (2 \leq X \leq 4) = \int_{2}^{4} \frac{5}{4x^{2}} \> dx &= \frac{5}{4} \int_{2}^{4} x^{-2} \> dx \\
    &= \frac{5}{4} \bigg[-x^{-1} \bigg]_{2}^{4} \\
    &= -\frac{5}{4} \bigg(\frac{1}{4} - \frac{1}{2} \bigg) \\
    &= \frac{5}{16} \\
\end{aligned}
$$

```{r q.02}
f <- function(x) {return (5/(4*x**2))}
integrate(f, 2, 4); 5/16
```

### q.03

**A.**
*Normalising constants (Book A, p.111)*

Normalising constant $K$ is given by

$$
    1 = \int_{-1}^{1} \frac{1}{K} \bigg( 1 + \frac{x}{2} \bigg) \> dx
      = \frac{1}{K} \int_{-1}^{1} \bigg( 1 + \frac{x}{2} \bigg) \> dx.
$$

Therefore, $K$ is

$$
\begin{aligned}
    K &= \bigg[ x + \frac{1}{2} \bigg(\frac{x^{2}}{2} \bigg) \bigg]_{-1}^{1} \\
      &= \bigg( 1 + \frac{1}{4} (1^{2}) - \bigg( -1 + \frac{1}{4} (-1)^{2} \bigg) \bigg) \\
      &= \bigg( \frac{5}{4} - \bigg( -\frac{3}{4} \bigg) \bigg) \\
      &= 2 \\
\end{aligned}
$$

```{r q.03}
f <- function (x) {(1/2)*(1+x/2)}  # declare the fn
integrate(f, -1, 1)  # integrate over range (0,1)
```


### q.04

**E.**
*Cumulative distribution functions of a discrete rv (HB p.7)*

The c.d.f. of $X$ at $x=3$ is given by

$$
F(x=3) = P(X \leq 3) = p(1) + p(2) + p(3) = 0.1 + 0.3 + 0.2 = 0.6.
$$

### q.05

**E.**
*Poisson distribution (HB p.8)*

The $P(X>2) = 1 - P(X \leq 2)$ is given by,

$$
\begin{aligned}
1 - P(X \leq 2) &= 1 - (p(0) + p(1) + p(2)) \\
  &= 1 - \sum_{i=0}^{2} e^{-\mu} \bigg( \frac{\mu^{x_{i}}}{x{i}!} \bigg) \\
  &= 1 - e^{-\mu} \sum_{i=0}^{2} \bigg( \frac{\mu^{x_{i}}}{x{i}!} \bigg) \\
  &= 1 - e^{-0.4} \bigg( \frac{0.4^{0}}{0!} + \frac{0.4^{1}}{1!} + \frac{0.4^{2}}{2!} \bigg) \\
  &= 1 - e^{-0.4} \bigg( 1 + 0.4 +  0.08 \bigg) \\
  &= 1 - 1.48 e^{-0.4}.
\end{aligned}
$$

```{r q.05}
# need to round the values to check equality
round(ppois(2, 0.4, lower.tail = FALSE), 6) ==
  round(1-1.48*exp(x = -0.4), 6)
```

### q.06

**F.**
*Mean of a linear function of rvs (HB p.9)*

For a random variable $Y=-2-2X$, then

$$
E(Y) = aE(X) + b,
$$

where $E(X) = 10$, $a = -2$, and $b=-2$.
Therefore,

$$
E(Y) = -2 (10) + (-2) = -20 - 2 = -22.
$$

### q.07

**E.**
*Variance a linear function of rvs (HB p.9)*

For a random variable $Y=-2-2X$, then

$$
S(Y) = \sqrt{V(Y)} = \sqrt{a^{2} V(X)} = |a| \sqrt{V(X)},
$$

where $V(X) = 9$ and $a = -2$.
Therefore

$$
S(Y) = |-2| \sqrt{9} = 6.
$$

### q.08

**B.**
*Poisson approximation of rare events (HB p.10)*

It is estimated that $p=1/420$ suffer from the disease and $n=2100$ employees work for the company.

Therefore, as $n \geq 50$ and $p \leq 0.05$, we can approximate the number of employees who suffer from the disease at the company as approximately

$$
B \bigg( 2100, \frac{1}{420} \bigg) \approx \text{Poisson} (np),
$$

where $np = 2100 (1/420) = 5$.
So a good approximation for the scenario would be $\text{Poisson} (5)$.

### q.09

**C.**
*Poisson process (HB p.10) and Poisson distribution (HB p.8)*

Let $X$ model the number of email arriving in the office per hour.
Then $X \sim \text{Poisson}(\mu)$, where $\mu = 3$ is the average number of emails received in an hour.

The probability $P(X=4)$ is given by

$$
\begin{aligned}
  p(4) = e^{-3} \bigg( \frac{3^{4}}{4!} \bigg) \simeq 0.168.
\end{aligned}
$$

```{r q.09}
dpois(4, 3)
```

### q.10

**B.**
*Poisson process (HB p.10) and Exponential distribution (HB p.10)*

Let $T$ model the waiting time between emails arriving in the office.
Then $T \sim M(\lambda)$, where $\lambda = 3$ is the average number of emails received in an hour.

Fifteen minutes is $1/4$ hours, so $P(T < 1/4)$ is given by

$$
\begin{aligned}
  P \bigg(T \leq \frac{1}{4} \bigg) = F\bigg(\frac{1}{4}\bigg) = 1 - e^{-3 \big( \frac{1}{4} \big)} \simeq 0.528.
\end{aligned}
$$

```{r q.10}
pexp(0.25, 3)
```

### q.11

**F.**
*Poisson process (HB p.10)*

The number of emails that will arrive in 6 hours is distributed $\text{Poisson}(\lambda t)$, where $\lambda = 3, t=6$.
So $\text{Poisson}(18)$.

### q.12

**B and F.**
*Bernoulli process (HB p.10), Poisson process (HB p.10), and Exponential distribution (HB p.10)*

A. True, in a **Bernoulli** process, the waiting time from one success up to and including the next success has a geometric distribution.

B. **False**, in a **Bernoulli** process, events occur in discrete trials.

C. True, in a **Bernoulli** process, the number of successes in $n$ trials has a binomial distribution.

D. True, in a **Poisson** process, the number of events that occur in a fixed time period has a Poisson distribution.

E. True, in a **Poisson** process, events occur singly.

F. **False**, if $X$ has an *exponential distribution* then $X \sim M(\lambda)$, and so $E(X) = 1/\lambda$.

### q.13

**C.**
*Population quantiles of a continuous rv (HB p.11)*

*Note, used $\alpha$ as rational rather than decimal due to the range of possible solutions.*

The $\alpha$-quantile of a continuous rv $X$ with c.d.f. $F(X)$ is defined as $F(x) = \alpha$.

If $F(x) = 2 - \frac{10}{x}, \> x \in (5,10)$, then the *median* is when $\alpha = 1/2$, so

$$
\begin{aligned}
  F(x) = \alpha \to 2 - \frac{10}{x} &= \frac{1}{2} \\
    2 - \frac{1}{2} &= \frac{10}{x} \\
    \frac{3}{2} &= \frac{10}{x} \\
    3x &= 20 \\
    x &= \frac{20}{3}.
\end{aligned}
$$

```{r q.13}
F <- function (x) {2 - 10/x}; F(x = 20/3)
```

### q.14

**E.**
*Population quantiles of a discrete rv (HB p.11)*

*Note, check if the table contains the $f(x)$ or $F(x)$*

The smallest value of $x \in X$ to satisfy $F(X) = q_{U} = \dfrac{3}{4}$ is $x=5$.

### q.15

**A.**
*Difference between two independent normal rvs (HB p.11)*

If $X \sim N(4,3)$, $Y \sim N(2,2)$, then $U = X - Y$ has the distribution:

$$
E(U) = E(X-Y) = E(X) - E(Y) = 4 - 2 = 2,
$$

and

$$
V(U) = V(X-Y) = V(X) + V(Y) = 3 + 2 = 5.
$$

So $U = X - Y \sim N(2, 5)$.

### q.16

**D.**
*Probabilities for any non-standard normal (HB p.12)*

If $X \sim N(22, 36)$, then the probability $P(X > 25)$ is given by

$$
\begin{aligned}
  P(X > 25) = 1 - P(X < 25) &= 1 - P\bigg(Z < \frac{25-22}{\sqrt{36}} \bigg) \\
    &= 1 - P\bigg(Z < \frac{1}{2} \bigg) \\
    &= 1 - \Phi(0.50) \\
    &\simeq 1 - 0.6915 = 0.3085.
\end{aligned}
$$

```{r q.16}
pnorm(25, 22, 6, lower.tail = FALSE)
```

### q.17

**F.**
*Quantiles of any non-standard normal (HB p.12)*

The volume of the container (in ml) that ensures overflow will only occur 1% of the time corresponds to the 0.99-quantile of the distribution of $X \sim N(1748.48, 20^{2})$, such that

$$
x = \sigma q_{0.99} + \mu,
$$

where $q_{0.99} = 2.326$ is the 0.99-quantile of the standard normal distribution.

Therefore,

$$
x = 20 (2.326) + 1748.48 = 1795.00.
$$

```{r}
qnorm(0.99, 1748.48, 20)
```

    # Error due to rounding in tables

### q.18

**A.**
*Sampling distribution of the mean (HB p.12) and Probabilities for any non-standard normal (HB p.12)*

If $X \sim N(10000, 500^{2})$, then $\overline{X}_{50}$ will be distributed

$$
E(\overline{X}_{50}) = \mu = 10000,
$$

and

$$
V(\overline{X}_{50}) = \frac{\sigma^{2}}{n} = \frac{500^{2}}{50} = 5000.
$$

Therefore, given $\overline{X}_{50} \sim N(10000, 5000)$, then the probability $P(\overline{X}_{50} < 9900)$ will be given by

$$
\begin{aligned}
  P(X < 9900) &= 1 - P \bigg( Z < \frac{9900-10000}{\sqrt{5000}} \bigg) \\
    &= P\bigg(Z < -\sqrt{2} \bigg) \\
    &\simeq \Phi(-1.41) \\
    &= 1 - \Phi(1.41) \\
    &= 1 - 0.9207 = 0.0793.
\end{aligned}
$$

```{r q.18}
pnorm(9900, 10000, sqrt(5000))
```

    # Error due to rounding in tables

### q.19

**A.**
*Unbiased estimators (HB p.13)*

If $E(X_{1}) = \theta$, $E(X_{2}) = 2\theta$, and $E(X_{3}) = 6\theta$, then an unbiased estimator for $/theta$ is such that

$$
E(\widehat \theta) = \theta.
$$

Looking at option A,

$$
\begin{aligned}
  E(\widehat \theta) &= E\bigg\{ \frac{1}{10}(2 X_{1} + X_{2} + X_{3}) \bigg\} \\
    &= \frac{1}{10} E\bigg\{ (2 X_{1} + X_{2} + X_{3}) \bigg\} \\
    &= \frac{1}{10} \{ E (2 X_{1}) + E (X_{2}) + E (X_{3}) \} \\
    &= \frac{1}{10} \{ 2 E (X_{1}) + E (X_{2}) + E (X_{3}) \} \\
    &= \frac{1}{10} \{ 2 \theta + 2 \theta + 6 \theta \} \\
    &= \frac{1}{10} \{ 10 \theta \} = \theta.
\end{aligned}
$$

Option A is unbiased, so we stop here.

### q.20

**C.**
*Exact confidence intervals for normal means (HB p.15)*

The upper limit of an exact 99% confidence interval for the mean $\mu^{+}$ is given by

$$
\mu^{+} = \overline{x} + t \frac{s}{\sqrt{n}},
$$

where $t$ is the $(1-(\alpha/2))$-quantile of $t(n-1)$.

We know

- $n=10$
- $\overline{x}=112.5$
- $s=35.1$
- $t=3.250$
  - $0.995$-quantile of the $t(9)$ distribution)

So the upper limit is given by

$$
\begin{aligned}
  \mu^{+} = 112.5 + 3.250 \bigg( \frac{35.1}{\sqrt{10}} \bigg) \simeq 148.6
\end{aligned}
$$

```{r}
tconfint_mean(a = 0.99, x = 112.5, sd = 35.1, n = 10)
```

### q.21

**C and F.**
*Anatomy of a hypothesis test (HB p.17) and $z$-test (HB p.17)*

A. False, critical value is $2.326$

B. False, this is a one-sided test $(H_{1} : \mu > \mu_{0})$

C. True, as the significance level decreases, the rejection region increases

D. False, $\overline{x} = 434.2$ and $\sigma = 1.1$, so null distribution is approximately $N(434.2, 1.1^{2}) \sim N(434.2, 1.21)$

E. False, rejection region is *as or more extreme*

F. True

### q.22

**B.**
*Calculating the test statistic for a $z$-test (HB p.17)*

The test statistic is

$$
  Z = \frac{\overline{X} - \mu_{0}}{S/\sqrt{n}} = \frac{434.2 - 433}{1.1/\sqrt{36}} \simeq 6.55.
$$

### q.23

**D.**
*Calculating the power of a test (HB p.18)*

The power of this two-sided test with a 5% significance level will be

$$
1 - \Phi \bigg( q_{1-(\alpha/2)} - \frac{d}{\sigma/\sqrt{n}} \bigg),
$$

where $q_{1-(\alpha/2)} = q_{0.975} = 1.960$, $d=0.6$, $\sigma=4.2$, and $n=196$.

Therefore, the power of the test will be

$$
\begin{aligned}
 1 - \Phi \bigg( 1.960 - \frac{0.6}{4.2/\sqrt{196}} \bigg)
  &\simeq 1 - \Phi (-0.4) \\
  &= 1 - (1 - \Phi (0.4) \\
  &= \Phi (0.4) \\
  &= 0.5160.
\end{aligned}
$$

```{r}
calc_test_power(a = 0.05, d = 0.6, sd = 4.2, n = 196, one_sided = FALSE)
```

### q.24

**C.**
*Chi-squared goodness-of-fit test (HB p.21)*

The degrees of freedom of a **chi-squared** goodness-of-fit test is $k-p-1$, where

- $k=4$ is the number of categories
- $p=0$ is the number of estimated parameters

Therefore the degrees of freedom is $4-0-1=3$.

### q.25

**F.**
Chi-squared goodness-of-fit test (HB p.21)

The **chi-squared** test statistic is

$$
\chi^{2} = \sum\frac{(O_{i} - E{i})^{2}}{E_i},
$$

so

$$
\chi^{2} = \frac{4.1^{2}}{106.9} + \dots + \frac{(-3.9)^{2}}{11.9} \simeq 1.53.
$$

```{r}
obs <- c(111, 37, 34, 8); exp <- c(106.9, 35.8, 35.4, 11.9)
calc_chi_sq(obs, exp)
```

### q.27

==Not answered==

### q.28

==Not answered==

### q.29

==Not answered==

## Section B

### q.30

*Cumulative distribution function of a continuous rv (HB p.7)*

If $f(x) = \frac{1}{78} (6x^{2} + 2x + 5)$, where $x \in (0,3)$, then the $F(x)$ will be

$$
\begin{aligned}
F(x) = \int_{0}^{x} \frac{1}{78} (6y^{2} + 2x + 5) \> dy
  &= \frac{1}{78} \int_{0}^{x} (6y^{2} + 2x + 5) \> dy \\
  &= \frac{1}{78} \bigg[ \frac{6}{3} y^{3} + \frac{2}{2} y^{2} + 5y \bigg]_{0}^{x} \\
  &= \frac{1}{78} \bigg[ 2 y^{3} + y^{2} + 5y \bigg]_{0}^{x} \\
  &= \frac{1}{78} ( 2 x^{3} + x^{2} + 5x - (0 + 0 + 0)) \\
  &= \frac{1}{78} (2 x^{3} + x^{2} + 5x).
\end{aligned}
$$

### q.31

Probability density functions (HB p.7)

If $F(x) = \frac{1}{80} (x^{2} + x^{3})$, then $P(1 \leq X \leq 2) = P(X \leq 2) - P(X \leq 1)$ will be given by

$$
\begin{aligned}
  P(X \leq 2) - P(X \leq 1) &= F(2) - F(1) \\
    &= \frac{1}{80} (2^{2} + 2^{3}) - \frac{1}{80} (1^{2} + 1^{3}) \\
    &= \frac{1}{80} ((4 + 8) - (1 + 1)) \\
    &= \frac{1}{80} (12 - 2) \\
    &= \frac{1}{80} (10) \\
    &= \frac{1}{8} = 0.125. \\
\end{aligned}
$$

```{r}
F <- function(x) {(1/80) * (x**2 + x**3)}; F(2) - F(1)
```

### q.32

#### (a)

*Geometric distribution (HB p.8)*

Let $X$ be a discrete rv that represents the number of people who need to pass through the metal detector until the next to activate it.
Then $X$ is modelled by the geometric distribution, $X \sim G(p)$, where $p=0.2$ is the probability that an individual activates the metal detector, so $X \sim G(0.4)$.

Tthe probability $P(X=4)$ is given by

$$
\begin{aligned}
  P(X=4) = (1-p)^{y-1} p = 0.8^{3} 0.2 = 0.1024.
\end{aligned}
$$

```{r q.32.a}
dgeom(x = 3, prob = 0.2)  # note, @param x -> (x-1) as defined by M248
```

#### (b)

*Binomial distribution (HB p.8)*

Let $Y$ be a discrete rv that represents the number of apples that passes through the metal detector.
Then $Y$ is modelled by the binomial distribution, $Y \sim B(n,p)$, where $n=10$ is the sample size and $p=0.2$ is the probability that an individual sets off the metal detector, so $Y \sim B(10,0.2)$.

The probability $P(X=3)$ is given by

$$
\begin{aligned}
  P(X=3) = \binom{n}{x} p^x (1-p)^{n-x} = \binom{10}{3} 0.2^{3} (0.8)^{7} \simeq 0.2013.
\end{aligned}
$$

```{r q.32.b}
dbinom(3, 10, 0.2)
```

### q.33

#### (a)

*Mean of a continuous rv (HB p.9)*

The expected value $E(X)$ of a continuous random variable $X$ is defined as

$$
E(X) = \int_{L}^{U} x \> f(x) \> dx, \hspace{3mm} x \in (L, U).
$$

Therefore,

$$
\begin{aligned}
  E(X) = \int_{0}^{1} x \frac{3}{2} (1 - x^{2}) &= \frac{3}{2} \int_{0}^{1} x - x^{3} \> dx \\
    &= \frac{3}{2} \bigg[ \frac{1}{2} x^{2} - \frac{1}{4} x^{4} \bigg]_{0}^{1} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{2} (1)^{2} - \frac{1}{4} (1)^{4} - \bigg( \frac{1}{2} (0)^{2} - \frac{1}{4} (0)^{4} \bigg) \bigg\} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{4} \bigg\} \\
    &= \frac{3}{8}. \\
\end{aligned}
$$

Therefore, $E(X)=3/8$.

#### (b)

*Variance of a continuous rv (HB p.9)*

The $E(X^{2})$ of a continuous random variable $X$ is defined as

$$
E(X^{2}) = \int_{L}^{U} x^{2} \> f(x) \> dx, \hspace{3mm} x \in (L, U).
$$

Therefore,

$$
\begin{aligned}
  E(X) = \int_{0}^{1} x^{2} \frac{3}{2} (1 - x^{2}) &= \frac{3}{2} \int_{0}^{1} x^{2} - x^{4} \> dx \\
    &= \frac{3}{2} \bigg[ \frac{1}{3} x^{3} - \frac{1}{5} x^{5} \bigg]_{0}^{1} \\
    &= \frac{3}{2} \bigg\{ \frac{1}{3} (1)^{3}- \frac{1}{5} (1)^{5} - \bigg( \frac{1}{3} (0)^{3} - \frac{1}{5} (0)^{5} \bigg) \bigg\} \\
    &= \frac{3}{2} \bigg( \frac{1}{15} \bigg) \\
    &= \frac{1}{5}. \\
\end{aligned}
$$

Therefore, $E(X^{2})=1/5$.

#### (c)

*Variance of a continuous rv (HB p.9)*

The variance $V(X)$ of a continuous random variable $X$ is defined as

$$
V(X) = E\{ (X-\mu)^{2} \} = E(X^{2}) - E(X)^{2}
$$

We know that $E(X) = 3/5$, $E(X^{2})=1/5$, so

$$
V(X) = \frac{1}{5} - \bigg( \frac{3}{8} \bigg)^{2}
  = \frac{1}{5} - \frac{9}{64} = \frac{19}{320} \simeq 0.059.
$$

Therefore, $V(X)=19/320 \simeq 0.059$, rounded to 3dp.

### q.34

#### (a)

Likelihood functions for discrete data (HB p.13)

Using the p.m.f. of a geometric distribution, if $p(x_{i}; \theta) = \theta(1-\theta)^{x_{i}-1}$, then the likelihood of $\theta$, $L(\theta)$, will be

$$
\begin{aligned}
  L(\theta) = \prod_{i=1}^{4} p(x_{i}; \theta) &= \theta(1-\theta)^{x_{1}-1} \times \theta(1-\theta)^{x_{2}-1} \times \theta(1-\theta)^{x_{3}-1} \times \theta(1-\theta)^{x_{4}-1} \\
    &= \theta(1-\theta)^{5-1} \times \theta(1-\theta)^{2-1} \times \theta(1-\theta)^{5-1} \times \theta(1-\theta)^{1-1} \\
    &= \theta \times \theta \times \theta \times \theta \times (1-\theta)^{4} \times (1-\theta)^{1} \times (1-\theta)^{4} \times (1-\theta)^{0} \\
    &= \theta^{4}  \times (1-\theta)^{4 + 1 + 4 + 0} \\
    &= (1-\theta)^{9} \theta^{4}. \\
\end{aligned}
$$

#### (b)

*Finding the MLE of an estimator (HB p.13)*

If $L(\theta) = (1-\theta)^{9} \theta^{4}$ then, by the **product rule**, $L'(\theta)$ will be given by

$$
\begin{aligned}
  L'(\theta) &= (1-\theta)^{9} \times 4 \theta^{3} + (-1) (9) (1-\theta)^{8} \theta^{4} \\
    &= 4 \theta^{3} (1-\theta)^{9} - 9 \theta^{4}  (1-\theta)^{8} \\
    &= \theta^{3} (1-\theta)^{8} ( 4 (1-\theta) - 9 \theta ) \\
    &= \theta^{3} (1-\theta)^{8} ( 4 - 4 \theta - 9 \theta ) \\
    &= (1-\theta)^{8} \theta^{3} ( 4 - 13 \theta ) \\
\end{aligned}
$$

This matches the expression given in the question.

#### (c)

*Finding the MLE of an estimator (HB p.13)*

The MLE of $\theta$, $\widehat \theta$, is the solution to

$$
L'(\theta) = (1-\theta)^{8} \theta^{3} ( 4 - 13 \theta ) = 0.
$$

Given the range of $\theta > 0$, then $\theta^{3}(1-\theta)^{8} > 0$, so this reduces to solving

$$
\begin{aligned}
  0 &= 4 - 13 \theta \\
  13 \> \theta  &= 4 \\
  \theta  &= \frac{4}{13} \simeq 0.3077.
\end{aligned}
$$

So $\widehat \theta \simeq 0.3077$.

### q.35

#### (a)

*Approximate large-sample intervals for the difference between two proportions (HB p.15)*

Let $n_{1} = 100, x_{1} = 33$ represent the sample from 2010, and $n_{2} = 150, x_{2} = 54$ represent the sample from 2013.
Then the point estimate of the difference $\widehat d$ between the two samples, such that

$$
\widehat d = p_{1} - p_{2} = \frac{33}{100} - \frac{54}{150} = 0.33 - 0.36 = -0.03.
$$

Therefore, an approximate *95%* confidence interval for the population difference,
$(d^{-}, d^{+})$, is given by

$$
\begin{aligned}
  d^{-} &= -0.03 - 1.96 \sqrt{ \frac{0.33(0.67)}{100} + \frac{0.36(0.64)}{150} } \\
    &\simeq -0.03 - 1.96 (0.0608) \\
    &\simeq -0.1492 \\
    &\simeq -0.15, \\
  d^{+} &= -0.03 + 1.96 \sqrt{ \frac{0.33(0.67)}{100} + \frac{0.36(0.64)}{150} } \\
    &\simeq -0.03 + 1.96 (0.0608) \\
    &\simeq 0.0891 \\
    &\simeq 0.09.
\end{aligned}
$$

Therefore, a realised approximate 95% confidence interval for this scenario would be $(-0.15, 0.09)$.

```{r q.35.a}
zconfint_diff_props(0.95, 33, 100, 54, 150)
```

    ## Error due to rounding

#### (b)

*Repeated experiments interpretation of confidence intervals (HB p.14)*

If this entire trial was repeated independently a large number of times, and on each occasion a 95% confidence interval for the difference between proportions were calculated, then about 95% of these intervals would contain the population value for the difference between the proportion of individuals that thought cannabis should be legalised in 2010 and the proportion of individuals that thought cannabis should be legalised in 2013.

#### (c)

*Interpreting confidence intervals (M248 Unit 8, activity 14)*

The approximate 95% confidence interval found was $(-0.15, 0.09)$.
Given this interval contains $0$, it suggests that there is no difference in the proportion of individuals that thought cannabis should be legalised between 2010 and 2013.

### q.36

#### (a)

*Setting up the null and alternative hypotheses (HB p.17) and The Wilcoxon signed rank test (HB p.19)*

Let $m$ denote the underlying population median difference in aluminium concentrations between August and November.
This is a two-sided test so the hypotheses are

$$
H_{0} : m = 0, \>  H_{1} : m \neq 0
$$

#### (b)

*Calculating the test statistic of the Wilcoxon signed rank test (HB p.19)*

| Tree                      | 1    | 2    | 3   | 4   | 5   | 6   | 7   | 8   | 9    | 10   | 11  | 12   | 13   |
|---------------------------|------|------|-----|-----|-----|-----|-----|-----|------|------|-----|------|------|
| Difference                | 12.0 | 12.3 | 3.1 | 7.2 | 5.3 | 1.0 | 6.3 | 0.0 | −2.2 | 23.4 | 2.0 | −1.2 | −5.6 |
| Sign of diff              | +    | +    | +   | +   | +   | +   | +   |     | -    | +    | +   | -    | -    |
| Abs value of diff         | 12.0 | 12.3 | 3.1 | 7.2 | 5.3 | 1.0 | 6.3 | 0.0 | 2.2  | 23.4 | 2.0 | 1.2  | 5.6  |
| Rank of abs value of diff | 10   | 11   | 5   | 9   | 6   | 1   | 8   |     | 4    | 12   | 3   | 2    | 7    |

The value of the test statistic is the sum of the ranks of the positivie differences, so

$$
w_{+} = 10 + 11 + 5 + 9 + 6 + 1 + 8 + 12 + 3 = 65.
$$

#### (c)

*Normal approximation to the null distribution of the Wilcoxon test statistic (HB p.20)*

Under the null hypothesis, for a sample of size $12$ (excluding the zero difference), the Wilcoxon signed rank test statistic $W_{+}$ has mean,

$$
\begin{aligned}
  E(W_{+}) = \frac{n(n+1)}{4} = \frac{12(13)}{4} = 39,
\end{aligned}
$$

and variance,

$$
\begin{aligned}
  V(W_{+}) = \frac{n(n+1)(2n+1)}{24} = \frac{12(13)(25)}{24} = 162.5.
\end{aligned}
$$

```{r}
# returns (z, Ew, Vw)
calc_norm_approx_wilcoxon(65, 12)
```

#### (d)

*Normal approximation to the null distribution of the Wilcoxon test statistic (HB p.20) and Interpreting $p$-values (HB p.18)*

In this scenario, the observed sum of ranks for the positive differences is $w_{+} = 65$, so the corresponding observed value of $Z$ is

$$
Z = \frac{w_{+} - E(W_{+})}{\sqrt{V(W_{+})}} = \frac{65-39}{\sqrt{162.5}} = 2.0396 \ldots \simeq 2.04.
$$

Using the table of probabilities of the standard normal distribution in the handbook gives

$$
P(Z \geq 2.04) = 1 - P(Z \leq 2.04) = 1 - 0.9793 = 0.0207.
$$

So, according to the approximation, the probability of obtaining a Wilcoxon signed rank test statistic of $65$ or greater is approximately $0.0207$.
For a two-sided test, the $p$-value is double this:

$$
P(Z \leq -2.04) + P(Z \geq 2.04) = 2 P(Z \geq 2.04) = 0.0414.
$$

Given that $p=0.0414$, there is moderate against the null hypothesis that there is no difference in aluminium concentrations in the wood of trees between August and November.
Looking at the data, the test statistic is large, so it seems that the population median difference in aluminium concentrations between August and November is greater than zero, suggesting that there is an increase in Aluminium concentrations.

### q.37

==Not answered==

### q.38

==Not answered==
